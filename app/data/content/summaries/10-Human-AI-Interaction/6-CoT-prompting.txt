Understanding Chain of Thought Prompting: Enhancing LLM Reasoning

OVERVIEW: STEP-BY-STEP REASONING FOR COMPLEX PROBLEMS

While working with a large language model like ChatGPT or Gemini AI, we often run into situations where the model gives a wrong answer. In such cases, we can force the LLM model to derive the solutions in a step-by-step manner to see how the model came up with the answer. To do this, we can use Chain of Thought prompting. Chain of Thought prompting enables LLM models to perform complex reasoning tasks by forcing the model to break them down into step-by-step logical sequences.

WHAT IS CHAIN OF THOUGHT PROMPTING?

When we encounter a complex problem, we often solve it by breaking it into smaller and simpler steps. For instance, if we have to solve a mathematical expression, we do this in a step-by-step manner by performing one operation at a time. Chain of Thought prompting is a prompt engineering technique where we use examples or instructions to improve the reasoning capabilities of an LLM model so that it can solve problems step by step.

In Chain of Thought prompting, the LLM model provides the result as well as the intermediate steps required to generate it, improving the LLM models' responses to problems requiring multiple reasoning and calculation steps.

HOW DOES CHAIN OF THOUGHT PROMPTING WORK?

Chain of thought prompting works by teaching the LLM applications to replicate human cognitive processes to solve problems. For this, we provide the models with specialized examples and instructions that help them generate the sequence of steps they take to solve a given problem.

For instance, suppose we have the problem "What is the value of 3+4+19-12?" with reasoning steps for its solution and the final answer. If we have to solve a new problem, "What is the value of 5 + 7 + 9 - 12?" we can provide the above example in the input prompt to help the LLM produce step-by-step reasoning with the output.

After looking at the example, the LLM model learns how to generate the reasoning sequence for the question we are asking. Instead of providing an example, we can ask the LLM application to provide the reasoning behind the output by giving a prompt like "Solve this problem step by step."

TYPES OF CHAIN OF THOUGHT PROMPTING

Based on how the LLMs are instructed to generate the reasoning sequence, we can classify Chain of Thought prompting techniques into three types: zero-shot Chain of Thought, few-shot Chain of Thought, and Automatic Chain of Thought.

ZERO-SHOT CHAIN-OF-THOUGHT PROMPTING

Zero-shot Chain of Thought is a prompting technique in which we tell the model to show the reasoning behind the output using instructions. In zero-shot Chain of Thought, we do not provide the LLM with examples. Instead, we instruct the LLM to generate a stepwise output using instructions like "Solve this problem step by step", "Let's think step by step", "Let's solve this step by step", "Let's work this out in a step-by-step manner", and similar phrases.

In zero-shot Chain of Thought, we do not give the LLM model any examples to learn from and generate step-by-step reasoning for a given problem. However, the model still generates reasoning sequences for its output. Sometimes, these reasoning steps might seem correct, but they might not make sense. To reduce the chances of the model producing illogical reasoning steps, we can provide a few examples of similar problems with reasoning steps and then ask the model to generate the reasoning, as done in few-shot Chain of Thought prompting.

FEW-SHOT CHAIN-OF-THOUGHT PROMPTING

In few-shot Chain of Thought, we give the LLM model some example problems and their reasoning sequences so that it can learn from them and logically generate the steps for a given problem of a similar form. In this prompt, we have given examples of problems similar to what we are trying to solve. After looking at the examples, the LLM model can identify how to generate the sequence of steps for the given question.

Few-shot Chain of Thought is more accurate than zero-shot Chain of Thought as we provide examples to the LLM model using which it learns to generate the reasoning sequences for a new problem. However, different types of questions require different examples, and manually designing examples for each type can be difficult. To automate the process and give examples for the different types of questions, we use Automatic Chain of Thought prompting.

AUTOMATIC CHAIN-OF-THOUGHT PROMPTING

The Automatic Chain of Thought prompting technique uses zero-shot Chain of Thought and few-shot Chain of Thought to generate reasoning sequences for a given problem. Automatic Chain of Thought follows these steps to help LLM models produce reasoning sequences.

First, we create a dataset of different types of questions. The dataset must have a variety of questions to help generate different types of reasoning sequences. Next, we group the questions into multiple clusters. For clustering the questions, you can use sentence transformer models to encode the questions and find the cosine similarity between them. Next, we choose one or two questions from each cluster and generate the reasoning chain for them using zero-shot Chain of Thought. After generating the reasoning sequences for the examples, we insert them into the prompt for the new questions. Here, the prompt will have different types of questions with their reasoning sequences. Hence, when we ask the LLM model to generate the steps of any question, it can refer to the most similar question and generate reasoning sequences based on that example.

In this example, we provided different problems with their reasoning steps. When presented with a new question, the model uses these examples to identify the most similar question and generate a reasoning sequence accordingly. Here, the example problems are selected from a dataset of problems, and their reasoning steps are generated using zero-shot Chain of Thought. Hence, this process is fully automated.

Studies have shown that Automatic Chain of Thought often outperforms both zero-shot and few-shot Chain of Thought in generating accurate reasoning sequences.

IMPLEMENTATION IN LANGCHAIN APPLICATIONS

To implement chain-of-thought prompting in LangChain, we will use prompt templates. Let's first see how the LLM model answers the question, "What is the value of 5+7+9-12?" without Chain of Thought. This code example shows that the LLM model returns only the final result without reasoning.

To generate reasoning sequences along with the final result, we can use zero-shot Chain of Thought. For this, we need to implement instructions like "Solve this problem step by step", "Let's think step by step", or "Let's solve this step by step" in the prompt template. In this example, we have used zero-shot Chain of Thought when asking to solve a math problem. Hence, the LLM application generates the reasoning sequence and the final output.

If you want the reasoning sequences in a particular format, you can guide the LLM model on generating the sequences using few-shot Chain of Thought. To do this, you can give some examples of the questions and their reasoning sequences in the prompt template. In this example, we gave questions and their reasoning sequence in the prompt template. The LLM model learns how to generate reasoning sequences using these examples and generates a similar sequence for the input query.

ADVANTAGES AND LIMITATIONS

Chain of Thought prompting has many advantages due to its ability to supervise the LLM models' output generation process. Chain of Thought prompting helps the LLM model break complex questions into small and simple steps. This allows the model to pay more attention to each part of the question and combine them to produce more accurate outputs. Chain of Thought also helps us understand how the LLM model solves a problem. By looking at the reasoning sequences, we can easily understand how the model proceeds to derive an output. Chain of Thought makes it easier for us to debug the LLM model when it produces wrong outputs. As we already know the reasoning sequence of the model, we can identify the exact step at which the model is making an error. Then, we can easily debug the output by prompting the model to correct the specific step.

Despite the above advantages, Chain of Thought fails to improve the performance of small-scale LLMs. Performance gains for Chain of Thought prompting are only visible for large-scale LLMs with a very large number of parameters. Small-scale models are likely to produce reasoning sequences that might seem logical but are incorrect, leading to worse performance than standard prompts.

CONCLUSION: ENHANCING REASONING CAPABILITIES

Chain of Thought prompting is a significant step in enhancing the reasoning capabilities of language models. It makes the LLMs more effective in tackling complex problems. You can use Chain of Thought in your LLM-based applications to improve the accuracy and interpretability of the results. This article covered implementing zero-shot and few-shot Chain of Thought in LangChain applications. To take it further, try implementing Automatic Chain of Thought for three or four types of questions. This hands-on approach will deepen your understanding of how Chain of Thought works and how to maximize its potential.
