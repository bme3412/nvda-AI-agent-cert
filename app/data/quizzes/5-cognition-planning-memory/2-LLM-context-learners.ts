import { QuizQuestion } from '../types';

export const questions: QuizQuestion[] = [
  {
    id: 'q1',
    question: 'What is the primary purpose of NeMo Guardrails according to the overview?',
    options: [
      'An open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems',
      'A commercial platform for deploying large language models in enterprise production environments',
      'A specialized database system for storing and retrieving conversational AI training data',
      'A cloud-based service for monitoring and analyzing large language model performance metrics'
    ],
    correctAnswer: 0,
    explanation: 'NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems, providing a specific way of controlling LLM output through runtime-defined rules.'
  },
  {
    id: 'q2',
    question: 'What approach does NeMo Guardrails take that differs from model alignment techniques?',
    options: [
      'Uses a runtime dialogue management approach with user-defined, LLM-independent, and interpretable programmable rails',
      'Implements reinforcement learning from human feedback during the initial model training process',
      'Applies prompt engineering and chain-of-thought reasoning directly within the language model architecture',
      'Utilizes fine-tuning and parameter adjustment to embed safety constraints into model weights permanently'
    ],
    correctAnswer: 0,
    explanation: 'NeMo Guardrails takes a different approach using a runtime inspired from dialogue management that allows developers to add programmable rails that are user-defined, independent of the underlying LLM, and interpretable, unlike model alignment that embeds rails during training.'
  },
  {
    id: 'q3',
    question: 'What is Colang and what role does it play in the NeMo Guardrails system?',
    options: [
      'A programming interface for integrating multiple language models into a single conversational system',
      'A custom modeling language used to define rules as dialogue flows that the LLM should follow',
      'A data format for storing and retrieving conversation histories and user interaction patterns',
      'A machine learning algorithm for automatically generating appropriate responses in dialogue systems'
    ],
    correctAnswer: 1,
    explanation: 'Colang is a custom modeling language used to define rules as dialogue flows that the LLM should always follow. It is interpreted by the dialogue manager to apply guardrails rules and guide LLM behavior.'
  },
  {
    id: 'q4',
    question: 'How does the NeMo Guardrails runtime function in relation to user interactions and LLM processing?',
    options: [
      'Acts like a proxy between the user and the LLM, interpreting and imposing predefined programmable rails',
      'Operates as a direct replacement for the language model, handling all conversational interactions independently',
      'Functions as a post-processing filter that modifies LLM outputs after they have been generated',
      'Serves as a preprocessing system that transforms user inputs before they reach the language model'
    ],
    correctAnswer: 0,
    explanation: 'The NeMo Guardrails runtime acts like a proxy between the user and the LLM, with the role of a dialogue manager that can interpret and impose the rules defining the programmable rails.'
  },
  {
    id: 'q5',
    question: 'What are the three main elements that comprise a Colang script configuration?',
    options: [
      'Input validation rules, output generation templates, and error handling mechanisms',
      'Authentication protocols, authorization policies, and session management configurations',
      'User canonical forms, dialogue flows, and bot canonical forms that define conversation structure',
      'Data preprocessing steps, model inference calls, and response post-processing operations'
    ],
    correctAnswer: 2,
    explanation: 'The main elements of a Colang script are user canonical forms, dialogue flows, and bot canonical forms, which are also indexed in a vector database for efficient nearest-neighbors lookup when selecting few-shot examples.'
  },
  {
    id: 'q6',
    question: 'How do canonical forms differ from traditional intents in conversational AI systems?',
    options: [
      'Canonical forms are generated by an LLM and not bound by closed sets, while intents are designed as closed sets for classification',
      'Canonical forms require manual definition by developers, while intents are automatically learned from training data',
      'Canonical forms focus exclusively on user emotions, while intents capture only factual content from conversations',
      'Canonical forms operate in real-time during conversations, while intents are processed offline in batch systems'
    ],
    correctAnswer: 0,
    explanation: 'The main difference is that intents are designed as a closed set for a text classification task, while canonical forms are generated by an LLM and thus are not bound in any way, but are guided by canonical forms defined by the Guardrails app.'
  },
  {
    id: 'q7',
    question: 'What are the two main categories of programmable rails that developers can implement?',
    options: [
      'Input rails for processing user messages and output rails for generating appropriate system responses',
      'Static rails with predefined rules and dynamic rails that adapt based on conversation context',
      'Topical rails for controlling dialogue and execution rails for calling custom actions with safety focus',
      'Local rails for single-turn interactions and global rails for maintaining context across multiple sessions'
    ],
    correctAnswer: 2,
    explanation: 'The two main categories are topical rails intended for controlling dialogue, such as guiding responses for specific topics, and execution rails that call custom actions defined by the app developer, with a focus on safety rails.'
  },
  {
    id: 'q8',
    question: 'What three main stages does the Guardrails runtime use for topical rails in conversation guidance?',
    options: [
      'Generate canonical form for user input, extract next steps or use LLM generalization, then generate conditioned response',
      'Validate user input format, check against security policies, then forward approved messages to the language model',
      'Parse conversation history, identify relevant context patterns, then apply appropriate response generation templates',
      'Classify user intent categories, select matching dialogue templates, then customize responses based on user profiles'
    ],
    correctAnswer: 0,
    explanation: 'The three stages are: first, generating the canonical form for user input using similarity-based few-shot prompting; second, extracting next steps from matching flows or using LLM generalization; third, generating responses conditioned by the next step.'
  },
  {
    id: 'q9',
    question: 'How does the fact-checking execution rail operate in NeMo Guardrails?',
    options: [
      'Formulates the task as an entailment problem, asking the LLM to predict if responses are grounded in evidence text',
      'Compares generated responses against a comprehensive database of verified factual statements',
      'Uses multiple independent language models to cross-validate the accuracy of generated content',
      'Implements real-time web search to verify claims made in language model responses'
    ],
    correctAnswer: 0,
    explanation: 'The fact-checking rail operates under the assumption of retrieval augmented generation, formulating the task as an entailment problem where the system asks the LLM to predict whether the response is grounded in and entailed by the evidence.'
  },
  {
    id: 'q10',
    question: 'What technique does the hallucination rail use to prevent the bot from making up facts?',
    options: [
      'Cross-referencing all generated statements against authoritative knowledge databases in real-time',
      'Using ensemble methods with multiple language models to identify and filter inconsistent responses',
      'Implementing uncertainty quantification to measure and reject responses with low confidence scores',
      'Self-consistency checking similar to SelfCheckGPT by sampling several answers and checking agreement'
    ],
    correctAnswer: 3,
    explanation: 'The hallucination rail uses self-consistency checking similar to SelfCheckGPT: given a query, the system samples several answers from the LLM and checks if these different answers are in agreement, as hallucinated statements produce disagreeing responses.'
  },
  {
    id: 'q11',
    question: 'What two key components make up the moderation process in NeMo Guardrails?',
    options: [
      'Input moderation (jailbreak rail) for detecting malicious messages and output moderation for detecting harmful responses',
      'Content filtering for inappropriate language and sentiment analysis for detecting negative emotional responses',
      'User authentication for verifying legitimate users and session monitoring for detecting suspicious behavior patterns',
      'Rate limiting for preventing system abuse and load balancing for maintaining optimal response performance'
    ],
    correctAnswer: 0,
    explanation: 'The moderation process contains input moderation (jailbreak rail) that detects potentially malicious user messages before reaching the dialogue system, and output moderation that detects whether LLM responses are legal, ethical, and not harmful.'
  },
  {
    id: 'q12',
    question: 'What evaluation dataset was used for testing topical rails performance?',
    options: [
      'The Stanford Question Answering Dataset with over 100,000 question-answer pairs',
      'A balanced dataset with 231 samples spanning 77 different intents from conversational NLU datasets',
      'A custom dataset of 500 multi-turn conversations collected from customer service interactions',
      'The Common Crawl corpus with filtered conversational exchanges from social media platforms'
    ],
    correctAnswer: 1,
    explanation: 'The evaluation used a balanced dataset containing at most 3 samples per intent randomly sampled from original datasets, with the test dataset having 231 samples spanning over 77 different intents from conversational NLU datasets.'
  },
  {
    id: 'q13',
    question: 'What performance results were achieved for moderation rails using both input and output rails?',
    options: [
      'GPT-3.5-turbo blocked close to 99% of harmful prompts and allowed 98% of helpful requests',
      'The system achieved 85% accuracy in distinguishing harmful from helpful content with minimal false positives',
      'Moderation rails reduced response latency by 40% while maintaining 95% accuracy in content filtering',
      'The combined approach achieved 92% precision and 88% recall across all moderation categories'
    ],
    correctAnswer: 0,
    explanation: 'Using both input and output moderation rails, GPT-3.5-turbo achieved great performance, blocking close to 99% of harmful prompts compared to 93% without rails, and blocking just 2% of helpful requests.'
  },
  {
    id: 'q14',
    question: 'What key limitation affects the cost and latency of using NeMo Guardrails?',
    options: [
      'The three-step CoT prompting approach incurs about 3 times the latency and cost of normal bot message generation',
      'Vector database lookups for canonical form matching require significant computational resources and storage capacity',
      'Real-time evaluation of multiple execution rails creates bottlenecks that scale poorly with conversation complexity',
      'Integration with external validation tools introduces network delays that significantly impact response times'
    ],
    correctAnswer: 0,
    explanation: 'The three-step CoT prompting approach used by the Guardrails runtime incurs extra costs and latency. The calls are sequentially chained and cannot be batched, resulting in about 3 times the latency and cost of a normal call.'
  },
  {
    id: 'q15',
    question: 'What future development approach does NeMo Guardrails envision for improving execution rails?',
    options: [
      'Providing more powerful customized models for execution rails to supplement current pure prompting methods',
      'Implementing distributed processing across multiple GPU clusters to reduce computational overhead significantly',
      'Developing automated machine learning pipelines that can generate custom rails without human intervention',
      'Creating standardized APIs for integrating third-party safety and content moderation services'
    ],
    correctAnswer: 0,
    explanation: 'The vision includes providing more powerful customized models for some of the execution rails that should supplement the current pure prompting methods, along with releasing p-tuned models for better performance on tasks like canonical form generation.'
  }
];